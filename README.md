# Obfuscation-Attack
The goal of an obfuscation (aka evasion) attack is to violate the integrity of a machine learning model.
